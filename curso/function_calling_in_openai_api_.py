# -*- coding: utf-8 -*-
"""Function_Calling_in_OPENAI_API_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vVL-m8y6BxpIztWgbf_AaACWIDN1j8BA

# Function Calling / Llamada de Funciones


Aprenda a conectar modelos de lenguaje grandes a herramientas externas.

##Introducción

La llamada de funciones le permite conectar modelos como gpt-4o a herramientas y sistemas externos. Esto es útil para muchas cosas, como dotar de capacidades a los asistentes de IA o crear integraciones profundas entre sus aplicaciones y los modelos.

En agosto de 2024, lanzamos `Structured Outputs`. Cuando lo activa configurando `strict: true` en la definición de su función, Structured Outputs garantiza que los argumentos generados por el modelo para una llamada de función coincidan exactamente con el esquema `JSON` que proporcionó en la definición de función.

## Ejemplos de casos de uso

La llamada de funciones es útil para una gran cantidad de casos de uso, como:

* Permitir que los asistentes obtengan datos: un asistente de IA debe obtener los datos más recientes de los clientes de un sistema interno cuando un usuario pregunta "¿cuáles son mis pedidos recientes?" antes de poder generar la respuesta al usuario.
* Permitir que los asistentes realicen acciones: un asistente de IA debe programar reuniones según las preferencias del usuario y la disponibilidad del calendario.
* Permitir que los asistentes realicen cálculos: un asistente de tutoría de matemáticas debe realizar un cálculo matemático.
* Crear flujos de trabajo completos: una canalización de extracción de datos que obtiene texto sin formato, luego lo convierte en datos estructurados y lo guarda en una base de datos.
* Modificar la interfaz de usuario de sus aplicaciones: puede usar llamadas de funciones que actualicen la interfaz de usuario según la entrada del usuario, por ejemplo, representar un pin en un mapa.

## El ciclo de vida de una llamada de función

Cuando se utiliza la API de OpenAI con llamadas de funciones, el modelo nunca ejecuta funciones por sí mismo, sino que en el paso 3 el modelo simplemente genera parámetros que se pueden utilizar para llamar a la función, que luego el código puede elegir cómo manejar, probablemente llamando a la función indicada. La aplicación siempre tiene el control total.

## Cómo usar la llamada de funciones

La llamada de funciones es compatible con la API de finalización de chat, la API de asistentes y la API de lotes. Esta guía se centra en la llamada de funciones mediante la API de finalización de chat. Tenemos una guía independiente para la llamada de funciones mediante la API de asistentes.

Para el siguiente ejemplo, estamos creando un asistente conversacional que puede ayudar a los usuarios con sus pedidos de entrega. En lugar de requerir que sus usuarios interactúen con un formulario típico, su usuario puede chatear con un asistente impulsado por IA. Para que este asistente sea útil, queremos darle la capacidad de buscar pedidos y responder con datos reales sobre los pedidos del usuario.

### Paso 1: Elija una función en su base de código que el modelo debería poder llamar

El punto de partida para la llamada de funciones es elegir una función en su propia base de código para la que le gustaría permitir que el modelo genere argumentos.

Para este ejemplo, imaginemos que desea permitir que el modelo llame a la función `get_delivery_date` en su código base, que acepta un `order_id` y consulta su base de datos para determinar la fecha de entrega de un paquete determinado. Su función podría verse así:
"""

# Instalación de librerías
#!pip install openai

"""## Preparación del ambiente

**IMPORTANTE**: Es importante proteger la key, de lo contrario pueden hacer mal uso de ella si alguien más la pudiera encontrar.
"""

import openai

# Opción 2.
openai.api_key = "sk-Lz-x44sWzTeiYJVLXtDrRcDgPlVQD4Ot3ePouROqiAT3BlbkFJYCrFTeP7SGD3WWsXTRtsjB5bieSVADEj3eHnF5rUAA"

openai.api_key

# This is the function that we want the model to be able to call
def get_delivery_date(order_id: str) -> datetime:
    # Connect to the database
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()
    # ...

"""### Paso 2: Describe tu función al modelo para que sepa cómo llamarla

Ahora que sabemos qué función queremos permitir que el modelo llame, crearemos una “definición de función” que describa la función al modelo. Esta definición describe tanto lo que hace la función (y potencialmente cuándo debe llamarse) como qué parámetros se requieren para llamar a la función.

La sección de parámetros de la definición de tu función debe describirse utilizando el esquema JSON. Si el modelo genera una llamada de función, utilizará esta información para generar argumentos de acuerdo con el esquema proporcionado.

En este ejemplo, podría verse así:
"""

{
    "name": "get_delivery_date",
    "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",
    "parameters": {
        "type": "object",
        "properties": {
            "order_id": {
                "type": "string",
                "description": "The customer's order ID.",
            },
        },
        "required": ["order_id"],
        "additionalProperties": false,
    }
}

"""### Paso 3: Pasa tus definiciones de funciones como "herramientas" disponibles al modelo, junto con los mensajes

A continuación, debemos proporcionar nuestras definiciones de funciones dentro de una matriz de `"herramientas"` disponibles al llamar a la API Chat Completions.

Como siempre, proporcionaremos una matriz de `"mensajes"`, que podrían contener, por ejemplo, tu mensaje o una conversación completa de ida y vuelta entre el usuario y un asistente.

Este ejemplo muestra cómo puedes llamar a la API Chat Completions proporcionando funciones y mensajes relevantes para un asistente que maneja consultas de clientes para una tienda.
"""

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_delivery_date",
            "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",
            "parameters": {
                "type": "object",
                "properties": {
                    "order_id": {
                        "type": "string",
                        "description": "The customer's order ID.",
                    },
                },
                "required": ["order_id"],
                "additionalProperties": False,
            },
        }
    }
]

messages = [
    {"role": "system", "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."},
    {"role": "user", "content": "Hi, can you tell me the delivery date for my order?"}
]

response = openai.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    tools=tools,
)

"""### Paso 4: Recibir y manejar la respuesta del modelo

Si el modelo decide que no se debe llamar a ninguna función
Si el modelo no genera una llamada a una función, la respuesta contendrá una respuesta directa al usuario de la forma habitual en que lo hace Chat Completions.

Por ejemplo, en este caso `chat_response.choices[0].message` puede contener:
"""

chat.completionsMessage(content='Hi there! I can help with that. Can you please provide your order ID?', role='assistant', function_call=None, tool_calls=None)

"""En un caso de uso de asistente, normalmente querrá mostrar esta respuesta al usuario y permitirle responderla, en cuyo caso llamará a la API nuevamente (con las últimas respuestas del asistente y del usuario adjuntadas a los mensajes).

Supongamos que nuestro usuario respondió con su ID de pedido y enviamos la siguiente solicitud a la API.
"""

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_delivery_date",
            "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",
            "parameters": {
                "type": "object",
                "properties": {
                    "order_id": {
                        "type": "string",
                        "description": "The customer's order ID."
                    }
                },
                "required": ["order_id"],
                "additionalProperties": False
            }
        }
    }
]

messages = []
messages.append({"role": "system", "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."})
messages.append({"role": "user", "content": "Hi, can you tell me the delivery date for my order?"})
// highlight-start
messages.append({"role": "assistant", "content": "Hi there! I can help with that. Can you please provide your order ID?"})
messages.append({"role": "user", "content": "i think it is order_12345"})
// highlight-end

response = client.chat.completions.create(
    model='gpt-4o',
    messages=messages,
    tools=tools
)

"""**Si el modelo generó una llamada de función**

Si el modelo generó una llamada de función, generará los argumentos para la llamada (según la definición de parámetros que proporcionó).

A continuación, se muestra un ejemplo de respuesta que muestra esto:
"""

Choice(
    finish_reason='tool_calls',
    index=0,
    logprobs=None,
    message=chat.completionsMessage(
        content=None,
        role='assistant',
        function_call=None,
        tool_calls=[
            chat.completionsMessageToolCall(
                id='call_62136354',
                function=Function(
                    arguments='{"order_id":"order_12345"}',
                    name='get_delivery_date'),
                type='function')
        ])
)

"""**Manejo de la respuesta del modelo que indica que se debe llamar a una función**

Suponiendo que la respuesta indica que se debe llamar a una función, su código ahora manejará esto:
"""

# Extract the arguments for get_delivery_date
# Note this code assumes we have already determined that the model generated a function call. See below for a more production ready example that shows how to check if the model generated a function call
tool_call = response.choices[0].message.tool_calls[0]
arguments = json.loads(tool_call['function']['arguments'])

order_id = arguments.get('order_id')

# Call the get_delivery_date function with the extracted order_id
delivery_date = get_delivery_date(order_id)

"""### Paso 5: Proporcionar el resultado de la llamada de función al modelo

Ahora que hemos ejecutado la llamada de función localmente, debemos proporcionar el resultado de esta llamada de función a la API de finalización de chat para que el modelo pueda generar la respuesta real que el usuario debería ver:
"""

# Simulate the order_id and delivery_date
order_id = "order_12345"
delivery_date = datetime.now()

# Simulate the tool call response
response = {
    "choices": [
        {
            "message": {
                "tool_calls": [
                    {"id": "tool_call_1"}
                ]
            }
        }
    ]
}

# Create a message containing the result of the function call
function_call_result_message = {
    "role": "tool",
    "content": json.dumps({
        "order_id": order_id,
        "delivery_date": delivery_date.strftime('%Y-%m-%d %H:%M:%S')
    }),
    "tool_call_id": response['choices'][0]['message']['tool_calls'][0]['id']
}

# Prepare the chat completion call payload
completion_payload = {
    "model": "gpt-4o",
    "messages": [
        {"role": "system", "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."},
        {"role": "user", "content": "Hi, can you tell me the delivery date for my order?"},
        {"role": "assistant", "content": "Hi there! I can help with that. Can you please provide your order ID?"},
        {"role": "user", "content": "i think it is order_12345"},
        response['choices'][0]['message'],
        function_call_result_message
    ]
}

# Call the OpenAI API's chat completions endpoint to send the tool call result back to the model
response = openai.chat.completions.create(
    model=completion_payload["model"],
    messages=completion_payload["messages"]
)

# Print the response from the API. In this case it will typically contain a message such as "The delivery date for your order #12345 is xyz. Is there anything else I can help you with?"
print(response)

"""Eso es todo lo que necesita para dar acceso a gpt-4o a sus funciones."""